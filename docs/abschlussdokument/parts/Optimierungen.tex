\section{Optimierungen}
Zusätzlich zu den algorithmischen Optimierungen und Parallelisierungsmöglichkeiten (OpenMP/C++Threads, CUDA, SSE/AVX, Datenstrukturen), haben wir untersucht, wo noch kleine Zeitgewinne herauszuholen sind.
Hierfür haben wir durch Analyse versucht, kritische Abschnitte in unserer Pipeline zu finden.
Dies haben wir zum Teil durch Benchmarking verschiedener Komponenten via Zeitmessung der Laufzeit intern oder durch unser Benchmarking-Tool und durch Benutzung von Profiling-Tools durchgeführt.
Kleinere Optimierungen umfassen beispielsweise das Cachen des Inversen der Richtung eines Strahls, da Divisionen insbesondere bei SSE/AVX sehr zeitaufwändig sind.

\subsection{Identifikation kritischer Abschnitte}
\label{ssec:crit-section}

Für die Identifikation kritischer Abschnitte haben wir zwei Werkzeuge verwendet. Am Anfang des Projektes benutzen wir Callgrind. Da dies aber bei großen Problemen eine sehr lange Laufzeit hat, haben wir im späteren Verlauf den \code{perf} Sampling-Profiler von Linux verwendet.

Wir benutzen den Samping-Profiler mit folgendem Aufruf:

\code{perf -e instructions:u -F 10000 ./pray ...}

Dadurch wird das Programm in einer Frequenz von $10000$ Hz unterbrochen und untersucht, an welcher Instruktion sich die Programmausfühtung gerade befindet. Die Häufigkeit, wie oft eine Instruktion angetroffen wurde gibt Aufschluss darüber, wie schnell sie ausgeführt wird. Allerdings können auch andere Effekte wie Pipeline-Stalls die Ursache sein, dass eine Instruktion länger dauert, daher muss auch immer die Menge der vorherigen Instruktionen mit in die Betrachtung einfließen.

Da es nichtsaussagend ist, die Geschwindigkeit der Debug-Version zu messen, haben wir immer unseren Release-Build getestet. Da unser Code (gewollt) so strukturiert ist, dass viele Methoden ge-"`inlined"' werden, fällt es schwer zu idendifizieren, zu welchem Teil des Codes ein gefundener heißer Pfad gehört. Manche Algorithmen lassen sich in der disassembly erkennen (z.B. das Skalarprodukt, die SSE-Variante außerdem durch die einzigartige Verwendung der \code{haddps} Instruktion). Andere Teile lassen sich idendifizieren durch Kompilierung mit \code{-S -g} Optionen und Vergleich von auffälligen Instruktionen.

\subsection{Heuristiken}
Wenige Dreiecke -> DummyAcceleration
Stackgröße Cuda, BIH...

\subsection{Subsampling}
Bei der Suche nach leistungssteigernden Maßnahmen haben wir uns unter anderem auch mit dem Thema Subsampling beschäftigt.
Das Cube-Beispiel bietet hierfür eine ideale Motivation, da über sehr große Bereiche nur der Hintergrund zu sehen ist, und man lediglich am Würfel selber alle Details abtasten möchte.
In unserem Raytracer stehen daher zur Compilezeit drei verschiedene Abtaststrategien zur Auswahl, die im folgenden näher beschrieben werden.

\subsubsection{Normales Sampling}
Zunächst haben wir nur das normale Abtasten der Szene mit je einem Strahl pro Ausgabebildpixel implementiert.
Hierzu gibt es abgesehen von der Parallelisierung des Ray-Castings mit OpenMP und dem Umgang mit verschiedenen Strahlengrößen nichts weiteres zu erwähnen.

\subsubsection{Interpolierendes Sampling}
Ein erstes naives Vorgehen um die Menge an verschossenen Strahlen bei gleicher Bildgröße zu verringern haben wir im "`interpolierenden Sampler"' implementiert.
Hierbei wird die Szene in einem Schachbrettmuster abgetastet, d.h. nur jeder zweite Strahl wird verschossen.
Anschließend werden die Lücken durch Interpolation aus den bis zu vier verschossenen Nachbarpixeln gefüllt.
Die Ränder stellen hierbei ein Problem dar, da ihnen (insbesondere bei Ecken) bis zu zwei tatsächlich abgetastete Nachbarpixel fehlen.
Die Interpolation wird außerdem naiv durchgeführt, also lediglich ein Mittelwert aus den angrenzenden Pixeln berechnet, um den interpolierten Farbwert zu erhalten.
Gerade an Kanten führt dies zu sägezahmusterartigen Artefakten.
Der interpolierende Sampler sorgt in der Praxis praktisch für eine Verdoppelung der Geschwindigkeit, was natürlich dadurch zustandekommt, dass nur die Hälfte der Arbeit auch wirklich vollbracht wird.
Dies ist durchaus als Schummelei zu werten, weswegen wir den interpolierenden Sampler auch niemals während der Benchmarks aktiviert hatten.

\subsubsection{Adaptives Sampling}
Obwohl weniger Arbeit verrichten, also Subsampling im Allgemeinen, wie bereits erwähnt definitiv nicht pauschal legal sein sollte, so kann man aus unserer Sicht aber argumentieren, dass es unter bestimmten Umständen doch legitim sein kann.
Unsere Raytracer haben nicht den Anspruch, Pixel-perfekte Ergebnisse zu liefern.
Insbesondere sorgen Fließkommaungenauigkeiten immer wieder dafür, dass Strahlen fälschlicherweise durch den (theoretisch nicht existenten) Spalt zwischen zwei Dreiecken durchschießen und die Szene so verlassen.
Unserer Ansicht nach ist es also legitim, bestimmte Sichtstrahlen zu überspringen, solange aktiv versucht wird zu vermeiden, dass relevante Bildinformation durch Unterabtastung verloren geht.
Genau hier setzt unsere Implementierung des "`adaptiven Subsamplers"' an:
Ähnlich wie im interpolierenden Sampler wird zunächst nur jeder zweite Strahl in einem Schachbrettmuster verschossen.
Doch statt anschließend lediglich zu interpolieren wird mithilfe einer Fehlerfunktion überprüft, ob die generelle Farbdiskrepanz in einem Fenster von gesampleten Pixeln oberhalb eines Schwellwerts liegt.
Sollte dies der Fall sein werden für alle bisher fehlenden Pixel noch einmal explizit Strahlen verschossen.
Wenn nicht, so wird im adaptiven Sampler genauso wie im interpolierenden Sampler für die fehlenden Bildpunkte ein Farbwert aus den umliegenden, abgetatsteten Pixeln berechnet.
Insbesondere an Kanten oder anderen hochfrequenten Bildbereichen, wo die Farbdiskrepanz zwischen Pixeln groß ist, sorgt dies dafür, dass die Bildinformation auch wirklich abgetastet wird.
Etwas besonderes ist, dass dies bei uns unter SSE auch mit SSE-Rays passiert, also Raypaketen.
Für diese gibt es unter dem adaptiven sampling nun einfach die Möglichkeit ein Raypaket mit doppelter größe sparse (also ohne jedes zweite Pixel) zu verschießen und dann im Falle eines zu hohen Error-Wertes durch ein inverses Cast den Rest zu berechnen.
